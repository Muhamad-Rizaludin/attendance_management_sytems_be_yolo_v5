{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Step 1: Install Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbvMlHd_QwMG",
        "outputId": "171b23f0-71b9-4cbf-b666-6fa2ecef70c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "YOLOv5 ðŸš€ v7.0-2-gc9d47ae Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 22.6/78.2 GB disk)\n"
          ]
        }
      ],
      "source": [
        "#clone YOLOv5 and\n",
        "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt # install dependencies\n",
        "%pip install -q roboflow\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# Step 2: Assemble Our Dataset\n",
        "\n",
        "Untuk melatih custom model, perlu menyusun dataset gambar representatif dengan anotasi kotak pembatas di sekitar objek yang ingin di deteksi.\n",
        "\n",
        "Di Roboflow, Anda dapat memilih di antara dua jalur:\n",
        "\n",
        "* Mengonversi kumpulan data yang ada ke format YOLOv5. Roboflow mendukung lebih dari [30 format format deteksi objek](https://roboflow.com/formats) untuk konversi.\n",
        "* Unggah gambar mentah dan beri anotasi di Roboflow dengan [Roboflow Annotate](https://docs.roboflow.com/annotate).\n",
        "\n",
        "\n",
        "# Annotate\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/roboflow-annotate.gif)\n",
        "\n",
        "# Version\n",
        "\n",
        "![](https://roboflow-darknet.s3.us-east-2.amazonaws.com/robolfow-preprocessing.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set up environment\n",
        "os.environ[\"DATASET_DIRECTORY\"] = \"/content/datasets\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR9ZbuQCH7FX",
        "outputId": "3f67f1c7-f15e-4fa5-d251-967c3b77eaad"
      },
      "outputs": [],
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"OOjFVJvJxMhClQMURd29\")\n",
        "project = rf.workspace(\"muhamad-rizaludin-2iyhw\").project(\"face-detection-for-attendance\")\n",
        "dataset = project.version(1).download(\"yolov5\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# Step 3: Train Our Custom YOLOv5 model\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** Our dataset locaiton is saved in the `dataset.location`\n",
        "- **weights:** specify a path to weights to start transfer learning from. Here we choose the generic COCO pretrained checkpoint.\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQPtK1QYVaD_",
        "outputId": "9d751d8c-bee8-4339-cf30-9854ca530449"
      },
      "outputs": [],
      "source": [
        "# Download COCO val\n",
        "!python train.py --img 416 --batch 16 --epochs 300 --data {dataset.location}/data.yaml --weights yolov5s.pt --cache"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance\n",
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile.\n",
        "\n",
        "If you are new to these metrics, the one you want to focus on is `mAP_0.5` - learn more about mean average precision [here](https://blog.roboflow.com/mean-average-precision/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X58w8JLpMnjH",
        "outputId": "a140d67a-02da-479e-9ddb-7d54bf9e407a"
      },
      "outputs": [],
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --data {dataset.location}/data.yaml  --img 416 --conf 0.4 --source {dataset.location}/test/images"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#display inference on ALL test images\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Validation for model\n",
        "\n",
        "ini digunakan untuk mengecek model yang telah di training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python val.py --data {dataset.location}/data.yaml --weights runs/train/exp/weights/best.pt --img 640 --half"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv5 Segmentation Tutorial",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
